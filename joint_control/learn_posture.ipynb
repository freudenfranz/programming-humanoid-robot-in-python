{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Posture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use machine learning to recognize robot's posture (following the example in [scikit-learn-intro.ipynb](./scikit-learn-intro.ipynb) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection\n",
    "\n",
    "We have colleceted data before, you need to add new data if you want to add new posture.\n",
    "\n",
    "* the dateset are in *robot_pose_data* folder\n",
    "* each file contains the data belongs to this posture, e.g. the data in *Back* file are collected when robot was in \"Back\" posture\n",
    "* the data file can be load by ```pickle```, e.g. ```pickle.load(open('Back'))```, the data is a list of feature data\n",
    "* the features (e.g. each row of the data) are ['LHipYawPitch', 'LHipRoll', 'LHipPitch', 'LKneePitch', 'RHipYawPitch', 'RHipRoll', 'RHipPitch', 'RKneePitch', 'AngleX', 'AngleY'], where 'AngleX' and 'AngleY' are body angle (e.g. ```Perception.imu```) and others are joint angles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pickle\n",
    "from os import listdir, path\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics\n",
    "\n",
    "ROBOT_POSE_DATA_DIR = 'robot_pose_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Knee', 'Crouch', 'StandInit', 'Sit', 'Right', 'Left', 'Belly', 'Stand', 'Frog', 'HeadBack', 'Back']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "    classes = listdir(ROBOT_POSE_DATA_DIR)\n",
    "print classes\n",
    "print len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pose_data(i):\n",
    "    '''load pose data from file'''\n",
    "    data = []\n",
    "    target = []\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    filename = path.join(ROBOT_POSE_DATA_DIR, classes[i])\n",
    "    data = pickle.load(open(filename))\n",
    "    target = [i] * len(data)\n",
    "    print \"Added %i datasets\"%len(data)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 10 datasets\n",
      "Added 30 datasets\n",
      "Added 52 datasets\n",
      "Added 26 datasets\n",
      "Added 11 datasets\n",
      "Added 20 datasets\n",
      "Added 19 datasets\n",
      "Added 11 datasets\n",
      "Added 10 datasets\n",
      "Added 10 datasets\n",
      "Added 23 datasets\n",
      "total number of data and targets:  222 222\n"
     ]
    }
   ],
   "source": [
    "# load all the data\n",
    "all_data = []\n",
    "all_target = []\n",
    "for i in range(len(classes)):\n",
    "    d, t = load_pose_data(i)\n",
    "    for j in range(len(d)):\n",
    "        all_data.append(d[j])\n",
    "        all_target.append(t[j])\n",
    "\n",
    "print 'total number of data and targets: ', len(all_data), len(all_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155(70%) +66(30%) =221\n"
     ]
    }
   ],
   "source": [
    "# shuffule data\n",
    "permutation = np.random.permutation(len(all_data))\n",
    "n_training_data = int(len(all_data) * 0.7)\n",
    "training_data = permutation[:n_training_data]\n",
    "rest = int(len(all_data) * 0.3)\n",
    "print str(n_training_data)+\"(70%) +\"+str(rest)+\"(30%) =\"+str(n_training_data+rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Learn on training data\n",
    "\n",
    "In scikit-learn, an estimator for classification is a Python object that implements the methods fit(X, y) and predict(T). An example of an estimator is the class sklearn.svm.SVC that implements support vector classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = np.array(training_data)\n",
    "all_data = np.array(all_data)\n",
    "all_target = np.array(all_target)\n",
    "clf.fit(all_data[training_data], all_target[training_data])\n",
    "#print all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10]), array([10]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(all_data[-1:]), all_target[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(expected, predicted):\n",
    "    print(\"Classification report:\\n%s\\n\" % metrics.classification_report(expected, predicted))\n",
    "\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       0.97      1.00      0.98        28\n",
      "          2       1.00      1.00      1.00        34\n",
      "          3       1.00      1.00      1.00        17\n",
      "          4       1.00      0.89      0.94         9\n",
      "          5       1.00      1.00      1.00        15\n",
      "          6       1.00      1.00      1.00        16\n",
      "          7       1.00      1.00      1.00         3\n",
      "          8       1.00      1.00      1.00         5\n",
      "          9       1.00      1.00      1.00         8\n",
      "         10       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       0.99      0.99      0.99       155\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 6  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 28  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 34  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 17  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  8  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 15  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 16  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  3  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  5  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  8  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 14]]\n"
     ]
    }
   ],
   "source": [
    "expected = []\n",
    "predicted = []\n",
    "# YOUR CODE HERE\n",
    "expected = all_target[training_data]\n",
    "predicted = clf.predict(all_data[training_data])\n",
    "evaluate(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         4\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00        18\n",
      "          3       1.00      1.00      1.00         9\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         5\n",
      "          6       1.00      1.00      1.00         3\n",
      "          7       1.00      1.00      1.00         8\n",
      "          8       1.00      1.00      1.00         5\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      1.00      1.00         9\n",
      "\n",
      "avg / total       1.00      1.00      1.00        67\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 4  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 18  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  9  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  5  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  3  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  5  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "expected = []\n",
    "predicted = []\n",
    "# YOUR CODE HERE\n",
    "predicted = clf.predict(all_data[permutation[n_training_data:]])\n",
    "expected = all_target[permutation[n_training_data:]]\n",
    "evaluate(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deploy to the real system\n",
    "\n",
    "We can simple use `pickle` module to serialize the trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "ROBOT_POSE_CLF = 'robot_pose.pkl'\n",
    "pickle.dump(clf, open(ROBOT_POSE_CLF, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, in the application we can load the trained classifier again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10]), array([10]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = pickle.load(open(ROBOT_POSE_CLF))\n",
    "clf2.predict(all_data[-1:]), all_target[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print clf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "widgets": {
   "state": {},
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
